{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import multiprocess \n",
    "from multiprocess import cpu_count\n",
    "from multiprocess import Pool\n",
    "from langdetect import detect_langs, DetectorFactory\n",
    "DetectorFactory.seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ocrs = os.path.abspath(\"../datasets/predict_categories_dataset_ocrs.jsonl.gz\")\n",
    "path_products = os.path.abspath(\"../datasets/predict_categories_dataset_products.jsonl.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_lang(dict_list):\n",
    "    \"\"\" get the language that has the highest confidence in 'detectedLanguages' \"\"\"\n",
    "    max_v = 0\n",
    "    main_lang = \"not_found\"\n",
    "    for dict_ in dict_list:\n",
    "        lang = dict_[\"languageCode\"]\n",
    "        if \"confidence\" in dict_:\n",
    "            confidence = dict_[\"confidence\"]\n",
    "        else: confidence = -1\n",
    "        if confidence > max_v:\n",
    "            max_v = confidence\n",
    "            main_lang = lang\n",
    "    return main_lang, max_v\n",
    "\n",
    "\n",
    "def get_row_for_df(json_line):\n",
    "    \"\"\" extract items from json and returns a row to put in a dataframe \"\"\"\n",
    "    code = json_line['code']\n",
    "    if \"ocrs\" in json_line:\n",
    "        langs = []\n",
    "        confidences = []\n",
    "        texts = []\n",
    "        keys =  list(json_line['ocrs'].keys())\n",
    "        for key in keys:\n",
    "            ocr_text = json_line['ocrs'][key]['text']\n",
    "            detected_langs = json_line['ocrs'][key]['detectedLanguages']\n",
    "            main_lang, confidence = get_main_lang(detected_langs)\n",
    "            texts.append(ocr_text)\n",
    "            langs.append(main_lang)\n",
    "            confidences.append(confidence)\n",
    "    row = [code, \"<end_of_text> \\n\".join(texts),  confidences, langs, keys]\n",
    "    return row\n",
    "\n",
    "\n",
    "def get_row_for_df_v2(json_line):\n",
    "    \"\"\" extract items from json and returns a row to put in a dataframe \"\"\"\n",
    "    code = json_line['code']\n",
    "    if \"ocrs\" in json_line:\n",
    "        langs = []\n",
    "        confidences = []\n",
    "        texts = []\n",
    "        keys =  list(json_line['ocrs'].keys())\n",
    "        for key in keys:\n",
    "            ocr_text = json_line['ocrs'][key]['text']\n",
    "            #detected_langs = json_line['ocrs'][key]['detectedLanguages']\n",
    "            main_lang, sorted_dict = text_lang_split(ocr_text)\n",
    "            text_main_lang = sorted_dict[main_lang][\"text\"]\n",
    "            confidence = np.mean(sorted_dict[main_lang][\"prob\"])\n",
    " \n",
    "            #main_lang, confidence = get_main_lang(detected_langs)\n",
    "            texts.append(text_main_lang)\n",
    "            langs.append(main_lang)\n",
    "            confidences.append(confidence)\n",
    "    row = [code, \"<end_of_text> \\n\".join(texts),  confidences, langs, keys]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artificial_sentence_split(text, n_words_per_sentence = 15):\n",
    "    \"\"\"splits artificially based on a pre-defined number of words. On average there are 15 words per sentence\"\"\"\n",
    "    txt_split = text.split()\n",
    "    total_words = len(txt_split)\n",
    "    if total_words >= n_words_per_sentence:\n",
    "        n_sentences = total_words // n_words_per_sentence\n",
    "        rest = total_words % n_words_per_sentence\n",
    "        chunks = [[i*n_words_per_sentence, (i+1)*n_words_per_sentence ] for i in range(n_sentences)]\n",
    "        chunks[-1][1]+=rest\n",
    "    else:\n",
    "        chunks = [[0, total_words]]\n",
    "    sentence_split = [\" \".join(txt_split[slice(*chunk)]) for chunk in chunks]\n",
    "    return sentence_split\n",
    "    \n",
    "def get_lang(text, threshold = 0.6):\n",
    "    \"\"\"takes text as input and returns main language detected if its probability is above the threshold\"\"\"\n",
    "    main_lang = 'not_found'\n",
    "    max_prob = 0\n",
    "    try :\n",
    "        langs = detect_langs(text)\n",
    "        for lang in langs:\n",
    "            if lang.prob > max(max_prob, threshold): \n",
    "                max_prob = lang.prob \n",
    "                main_lang = lang.lang\n",
    "    except:\n",
    "        main_lang = \"not_found\"\n",
    "        max_prob = 0\n",
    "\n",
    "    return main_lang, max_prob\n",
    "    \n",
    "def text_lang_split(text:str):\n",
    "    \"\"\"\n",
    "    takes text as input and splits it in a dictionnary with languages as keys.\n",
    "    for each language we have subkeys such as:\n",
    "    text: text found with the given language\n",
    "    len_text: the length of the text\n",
    "    prob: a list of probabilities, each probability corresponds to a sentence.  \n",
    "    \"\"\"\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(\"\\.+\", \".\", text)\n",
    "    lang_dict = {}\n",
    "    for sentence in artificial_sentence_split(text):\n",
    "        lang, prob = get_lang(sentence)\n",
    "        if lang in lang_dict:\n",
    "            lang_dict[lang][\"prob\"].append(prob)\n",
    "            lang_dict[lang][\"len_text\"] += len(sentence)\n",
    "            lang_dict[lang][\"text\"]+= sentence\n",
    "            \n",
    "        else:\n",
    "            lang_dict[lang] = {}\n",
    "            lang_dict[lang][\"prob\"] = [prob]\n",
    "            lang_dict[lang][\"len_text\"] = len(sentence)\n",
    "            lang_dict[lang][\"text\"] = sentence\n",
    "            \n",
    "    sorted_dict = {k: v for k, v in sorted(lang_dict.items(), key=lambda item: item[1][\"len_text\"], reverse = True)}\n",
    "    main_lang = next(iter(sorted_dict))\n",
    "    return main_lang, sorted_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0253028036418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Valeurs nutritionnelles moyennes pour 100 g : |Énergie Matières grasses dont acides gras saturés 826 kJ soit 198 kcal 12 g 2,3 g 0,6 g 0,6 g < 0,5 g 21 g Glucides dont sucres Fibres alimentaires Protéines Sel 2g  Saveurs FRANCRS JAMBON CUIT À L'ANCIENNE BLEU BLANC COEUR Ppale Cul chon b OGM09 Fprte en A consommer jungu 19.08.20 Numéro de Lot : 02020407 Prix/kg 19.90€ 0,279kg 5,55€ o 12536281036418 \""
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.choice(range(len(df)))\n",
    "t = df.iloc[i,0]\n",
    "barcode = df.index[i]\n",
    "print(barcode)\n",
    "t = re.sub(r\"\\n\", \" \", t)\n",
    "t = re.sub(\"\\.+\", \".\", t)\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_barcode(barcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"L'ANCIENNE BLEU BLANC COEUR Ppale Cul chon b OGM09 Fprte en A consommer jungu 19.08.20 Numéro de Lot : 02020407 Prix/kg 19.90€ 0,279kg 5,55€ o 12536281036418\""
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artificial_sentence_split(t)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "#rows = []\n",
    "\n",
    "with gzip.open(path_ocrs) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        #if i > 10000: # first 10 000 lines are potentially problematic we keep only further lines\n",
    "        if i > len(rows) - 1:\n",
    "            json_line = json.loads(line)\n",
    "            row = get_row_for_df_v2(json_line)\n",
    "            rows.append(row)\n",
    "df = pd.DataFrame(rows, columns = [\"code\", \"texts\", \"confidences\", \"langs\", \"keys\"])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2', '1', '3'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_line[\"ocrs\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after removing non normalized codes (643360, 5)\n",
      "after removing short texts (643360, 5)\n"
     ]
    }
   ],
   "source": [
    "### Keep only real codes i.e codes with length = 13 characters.\n",
    "real_codes =  df[\"code\"].str.len() == 13\n",
    "df = df[real_codes]\n",
    "print(\"after removing non normalized codes\", df.shape)\n",
    "### Keep only texts > 10 char\n",
    "len_sup_10 = (df[\"texts\"].str.len()> 10)\n",
    "df = df[len_sup_10]\n",
    "print(\"after removing short texts\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor(x:int)->int:\n",
    "    if x >= 1000:\n",
    "        x = 1000\n",
    "    return x\n",
    "def make_score(confidences):\n",
    "    if len(confidences)==1:\n",
    "        malus = 0.7\n",
    "    else:\n",
    "        malus = 1\n",
    "    return np.mean(confidences)*malus\n",
    "\n",
    "def get_most_confident_lang(confidences, langs, texts):\n",
    "    \"\"\"\n",
    "    get the language that has a good balance between confidence and length\n",
    "    score = confidence_mean * text_len. if text_len > 600 then text_len = 600\n",
    "    \"\"\"\n",
    "    D = {}\n",
    "    for conf, lang, text in zip(confidences, langs, texts.split(\"<end_of_text> \\n\")):\n",
    "        if lang in D:\n",
    "            D[lang][\"confidences\"].append(conf)\n",
    "            D[lang][\"text_len\"] += len(text)\n",
    "        else:\n",
    "            D[lang] = {}\n",
    "            D[lang][\"confidences\"] = [conf]\n",
    "            D[lang][\"text_len\"] = len(text)\n",
    "    output_dict = {lang: make_score(D[lang]['confidences'])*floor(D[lang]['text_len']) for lang in D}\n",
    "    lang_to_keep = max(output_dict, key = output_dict.get)\n",
    "    lang_to_keep_confidence = np.mean(D[lang][\"confidences\"])\n",
    "    return lang_to_keep, lang_to_keep_confidence, D, output_dict\n",
    "\n",
    "def extract_text_with_lang(langs, lang_to_keep, text, split_key = \"<end_of_text> \\n\"):\n",
    "    to_pick = np.where(np.array(langs) ==lang_to_keep)[0]\n",
    "    text_as_a_list = text.split(split_key)\n",
    "    output_text = \" \".join([text_as_a_list[i] for i in to_pick])\n",
    "    return output_text\n",
    "\n",
    "def extract_text_with_lang_from_df(df):\n",
    "    extracted_texts = []\n",
    "    lang_to_keep_list = []\n",
    "    lang_to_keep_confidence_list = []\n",
    "    for confidences, langs, texts in zip(df[\"confidences\"], df[\"langs\"], df[\"texts\"]):\n",
    "        lang_to_keep, lang_to_keep_confidence, _, _ = get_most_confident_lang(confidences, langs, texts)\n",
    "        output_text = extract_text_with_lang(langs, lang_to_keep, texts, split_key = \"<end_of_text> \\n\")\n",
    "        #append items\n",
    "        extracted_texts.append(output_text)\n",
    "        lang_to_keep_list.append(lang_to_keep)\n",
    "        lang_to_keep_confidence_list.append(lang_to_keep_confidence)\n",
    "    return extracted_texts, lang_to_keep_list, lang_to_keep_confidence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48, 0.66, 0.79, 0.56, 0.6, 0.46, 0.19, 0.88, 0.87, 1, 1, 1, 0.94]\n",
      "['es', 'pt', 'it', 'en', 'no', 'en', 'de', 'no', 'en', 'hr', 'nl', 'de', 'en']\n",
      "['13', '12', '11', '21', '17', '8', '9', '16', '20', '15', '18', '14', '4']\n"
     ]
    }
   ],
   "source": [
    "index = 18241\n",
    "c = df.loc[index, \"confidences\"]\n",
    "l = df.loc[index, \"langs\"]\n",
    "text = df.loc[index, \"texts\"]\n",
    "print(df.loc[index, \"confidences\"])\n",
    "print(df.loc[index, \"langs\"])\n",
    "print(df.loc[index, \"keys\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang_to_keep: de\n",
      "lang_to_keep confidence: 0.7075\n",
      "{'es': {'confidences': [0.48], 'text_len': 121}, 'pt': {'confidences': [0.66], 'text_len': 101}, 'it': {'confidences': [0.79], 'text_len': 85}, 'en': {'confidences': [0.56, 0.46, 0.87, 0.94], 'text_len': 643}, 'no': {'confidences': [0.6, 0.88], 'text_len': 315}, 'de': {'confidences': [0.19, 1], 'text_len': 1313}, 'hr': {'confidences': [1], 'text_len': 30}, 'nl': {'confidences': [1], 'text_len': 28}}\n",
      "--\n",
      "{'es': 40.656, 'pt': 46.662, 'it': 47.004999999999995, 'en': 454.9225, 'no': 233.1, 'de': 595.0, 'hr': 21.0, 'nl': 19.599999999999998}\n",
      "EN CONTAINS BARLEY MALT, WHEAT BEST BEFORE: SE\n",
      "BOTTLENECK\n",
      "DE ENTHALT: GERSTENMALZ, WEIZEN MINDESTENS HAITRAD\n",
      "CH BIS SIEHE FLASCHENHALS IN CH IMPORTIERT VON\n",
      "AT HEINEKEN SWITZERLAND AG, OBERGRUNDSTRASSE 110\n",
      "CH-6002 LUZERN VOR WARME UND LICHT GESCHUTZT\n",
      "LAGERN\n",
      "FR CONTIENT MALT D'ORGE, BLE-A CONSOMMER DE\n",
      "PREFERENCE AVANT LE: VOIR COL BIERE IMPORTEE PAR\n",
      "HEINEKEN ENTREPRISE BP 43-92 502 RUEIL-MALMAISON\n",
      "CEDEX\n",
      "IT CONTIENE: MALTO D'ORZO, FRUMENTO, GLUTINE\n",
      "DA CONSUMARSI PREFERIBILMENTE ENTRO IL: VEDI COLLO\n",
      "DELLA BOTTIGLIA IMPORTATA DA DIBEVIT IMPORT S.R.L\n",
      "VIALE EDISON N 110, SESTO SAN GIOVANNI (MI), ITALIA\n",
      "NL BEVAT: GERSTEMOUT,TARWE TEN MINSTE HOUDBAAR\n",
      "TOT:ZIE FLESSENHALS IMPORTEUR: EAST &WEST COMPANY\n",
      "ANTWOORDNUMMER 19090, 2300 VD ZOETERWOUDE\n",
      "ES CONTIENE MALTA DE CEBADA. TRIGO CONSUMIR\n",
      "PREFERENTEMENTE ANTES DEL: VER BOTELLA\n",
      "ANDALUCIA, 1, SEVILLA\n",
      "PREFERENCIA ANTES DE: VER GARRAFA\n",
      "NETHERLANDS\n",
      "DISTRIBUIDA POR HEINEKEN ESPAÑA S.A. AVDA. UE\n",
      "PT CONTEM: MALTE DE CEVADA, TRIGO CONSUMIR DE\n",
      "IMPORTADA POR/IMPORTED TO EU BY: HBBV, TWEEDE\n",
      "WETERINGPLANTSOEN 21, 1017 ZD, AMSTERDAM, THE\n",
      "BREWED BY/GEBRAUT VON/BRASSÉE PAR/PRODOTTA DA\n",
      "GEBROUWEN DOOR/ELABORADA POR/PRODUZIDO POR\n",
      "THE LAGUNITAS BREWING COMPANY\n",
      "1280 N. MCDOWELL BLVD. PETALUMA, CALIF. U.S.OF A\n",
      "LAGUNITAS@LAGUNITAS.COM\n",
      "0001034031707\n",
      " ENTHALT.GERSTENMALZ, WEIZEN I\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lang_to_keep, lang_to_keep_confidence, D, O = get_most_confident_lang(c, l, text)\n",
    "print(\"lang_to_keep:\", lang_to_keep)\n",
    "print(\"lang_to_keep confidence:\", lang_to_keep_confidence)\n",
    "print(D)\n",
    "print(\"--\")\n",
    "print(O)\n",
    "output_text = extract_text_with_lang(l, lang_to_keep, text, split_key = \"<end_of_text> \\n\")\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>lang_kept</th>\n",
       "      <th>lang_kept_confidence</th>\n",
       "      <th>texts</th>\n",
       "      <th>langs</th>\n",
       "      <th>confidences</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0041498293222</th>\n",
       "      <td>\"Percent Daily Values are based on a 2000\\nNut...</td>\n",
       "      <td>en</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Percent Daily Values are based on a 2000\\nNut...</td>\n",
       "      <td>[en]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0041498310424</th>\n",
       "      <td>INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...</td>\n",
       "      <td>[en, en, en]</td>\n",
       "      <td>[1, 0.75, 0.93]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0041500007007</th>\n",
       "      <td>Réf 0361 Moutarde French jaune\\nIngrédients: v...</td>\n",
       "      <td>fr</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1901\\nSince\\n100% NATURA\\nClassic\\nMUSTARD\\n80...</td>\n",
       "      <td>[en, fr]</td>\n",
       "      <td>[1, 0.93]</td>\n",
       "      <td>[1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0041500007229</th>\n",
       "      <td>INGREDIENTS: SPIRIT VINEGAR,\\nWATER, MUSTARD S...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>INGREDIENTS: SPIRIT VINEGAR,\\nWATER, MUSTARD S...</td>\n",
       "      <td>[en, fr, en, en, en, en, de]</td>\n",
       "      <td>[0.84, 1, 0.54, 0.71, 0.7, 1, 0.57]</td>\n",
       "      <td>[8, 2, 9, 5, 7, 1, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0041500013107</th>\n",
       "      <td>Poids net:295 m\\ninarédients: vinaiore distilé...</td>\n",
       "      <td>fr</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>Poids net:295 m\\ninarédients: vinaiore distilé...</td>\n",
       "      <td>[fr, fr, en]</td>\n",
       "      <td>[1, 0.9, 0.9]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0872513001795</th>\n",
       "      <td>Nestle\\nCocoe\\nPer bar\\nEnergy\\n192kcal\\n10\\nf...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>Nestle\\nCocoe\\nPer bar\\nEnergy\\n192kcal\\n10\\nf...</td>\n",
       "      <td>[en, en]</td>\n",
       "      <td>[0.85, 0.8]</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0040232618994</th>\n",
       "      <td>OLIVE OIL\\nNutrition Facts\\n133 Servings Per C...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>OLIVE OIL\\nNutrition Facts\\n133 Servings Per C...</td>\n",
       "      <td>[en, en]</td>\n",
       "      <td>[0.85, 0.95]</td>\n",
       "      <td>[2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0646670532245</th>\n",
       "      <td>FISH\\nMARKET\\nYarm Ruised\\nTILAPIA\\nFILLETS\\n5...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>FISH\\nMARKET\\nYarm Ruised\\nTILAPIA\\nFILLETS\\n5...</td>\n",
       "      <td>[en]</td>\n",
       "      <td>[0.81]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0034000993895</th>\n",
       "      <td>64\\nPIECES\\nNUT\\nLOVER'S\\nSNACK SIZE ASSORTMEN...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>64\\nPIECES\\nNUT\\nLOVER'S\\nSNACK SIZE ASSORTMEN...</td>\n",
       "      <td>[en]</td>\n",
       "      <td>[0.69]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0014800318296</th>\n",
       "      <td>CONTAINS 54% JUICE GLUTEN FREE\\nNutrition Fact...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>CONTAINS 54% JUICE GLUTEN FREE\\nNutrition Fact...</td>\n",
       "      <td>[en, en]</td>\n",
       "      <td>[0.81, 0.87]</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643360 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  extracted_text lang_kept  \\\n",
       "code                                                                         \n",
       "0041498293222  \"Percent Daily Values are based on a 2000\\nNut...        en   \n",
       "0041498310424  INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...        en   \n",
       "0041500007007  Réf 0361 Moutarde French jaune\\nIngrédients: v...        fr   \n",
       "0041500007229  INGREDIENTS: SPIRIT VINEGAR,\\nWATER, MUSTARD S...        en   \n",
       "0041500013107  Poids net:295 m\\ninarédients: vinaiore distilé...        fr   \n",
       "...                                                          ...       ...   \n",
       "0872513001795  Nestle\\nCocoe\\nPer bar\\nEnergy\\n192kcal\\n10\\nf...        en   \n",
       "0040232618994  OLIVE OIL\\nNutrition Facts\\n133 Servings Per C...        en   \n",
       "0646670532245  FISH\\nMARKET\\nYarm Ruised\\nTILAPIA\\nFILLETS\\n5...        en   \n",
       "0034000993895  64\\nPIECES\\nNUT\\nLOVER'S\\nSNACK SIZE ASSORTMEN...        en   \n",
       "0014800318296  CONTAINS 54% JUICE GLUTEN FREE\\nNutrition Fact...        en   \n",
       "\n",
       "               lang_kept_confidence  \\\n",
       "code                                  \n",
       "0041498293222              1.000000   \n",
       "0041498310424              0.893333   \n",
       "0041500007007              0.930000   \n",
       "0041500007229              0.570000   \n",
       "0041500013107              0.900000   \n",
       "...                             ...   \n",
       "0872513001795              0.825000   \n",
       "0040232618994              0.900000   \n",
       "0646670532245              0.810000   \n",
       "0034000993895              0.690000   \n",
       "0014800318296              0.840000   \n",
       "\n",
       "                                                           texts  \\\n",
       "code                                                               \n",
       "0041498293222  \"Percent Daily Values are based on a 2000\\nNut...   \n",
       "0041498310424  INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...   \n",
       "0041500007007  1901\\nSince\\n100% NATURA\\nClassic\\nMUSTARD\\n80...   \n",
       "0041500007229  INGREDIENTS: SPIRIT VINEGAR,\\nWATER, MUSTARD S...   \n",
       "0041500013107  Poids net:295 m\\ninarédients: vinaiore distilé...   \n",
       "...                                                          ...   \n",
       "0872513001795  Nestle\\nCocoe\\nPer bar\\nEnergy\\n192kcal\\n10\\nf...   \n",
       "0040232618994  OLIVE OIL\\nNutrition Facts\\n133 Servings Per C...   \n",
       "0646670532245  FISH\\nMARKET\\nYarm Ruised\\nTILAPIA\\nFILLETS\\n5...   \n",
       "0034000993895  64\\nPIECES\\nNUT\\nLOVER'S\\nSNACK SIZE ASSORTMEN...   \n",
       "0014800318296  CONTAINS 54% JUICE GLUTEN FREE\\nNutrition Fact...   \n",
       "\n",
       "                                      langs  \\\n",
       "code                                          \n",
       "0041498293222                          [en]   \n",
       "0041498310424                  [en, en, en]   \n",
       "0041500007007                      [en, fr]   \n",
       "0041500007229  [en, fr, en, en, en, en, de]   \n",
       "0041500013107                  [fr, fr, en]   \n",
       "...                                     ...   \n",
       "0872513001795                      [en, en]   \n",
       "0040232618994                      [en, en]   \n",
       "0646670532245                          [en]   \n",
       "0034000993895                          [en]   \n",
       "0014800318296                      [en, en]   \n",
       "\n",
       "                                       confidences                   keys  \n",
       "code                                                                       \n",
       "0041498293222                                  [1]                    [1]  \n",
       "0041498310424                      [1, 0.75, 0.93]              [2, 1, 3]  \n",
       "0041500007007                            [1, 0.93]                 [1, 3]  \n",
       "0041500007229  [0.84, 1, 0.54, 0.71, 0.7, 1, 0.57]  [8, 2, 9, 5, 7, 1, 6]  \n",
       "0041500013107                        [1, 0.9, 0.9]              [2, 1, 3]  \n",
       "...                                            ...                    ...  \n",
       "0872513001795                          [0.85, 0.8]                 [1, 2]  \n",
       "0040232618994                         [0.85, 0.95]                 [2, 1]  \n",
       "0646670532245                               [0.81]                    [1]  \n",
       "0034000993895                               [0.69]                    [1]  \n",
       "0014800318296                         [0.81, 0.87]                 [1, 2]  \n",
       "\n",
       "[643360 rows x 7 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_texts, lang_to_keep_list, lang_to_keep_confidence_list = extract_text_with_lang_from_df(df)\n",
    "df[\"extracted_text\"] = extracted_texts\n",
    "df[\"lang_kept\"] = lang_to_keep_list\n",
    "df[\"lang_kept_confidence\"] = lang_to_keep_confidence_list\n",
    "cols_order = [\"code\", \"extracted_text\", \"lang_kept\", \"lang_kept_confidence\", \"texts\", \"langs\", \"confidences\",\"keys\"]\n",
    "df = df[cols_order]\n",
    "df = df.set_index('code', drop = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>lang_kept</th>\n",
       "      <th>lang_kept_confidence</th>\n",
       "      <th>texts</th>\n",
       "      <th>langs</th>\n",
       "      <th>confidences</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0041498293222</th>\n",
       "      <td>\"Percent Daily Values are based on a 2000\\nNut...</td>\n",
       "      <td>en</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Percent Daily Values are based on a 2000\\nNut...</td>\n",
       "      <td>[en]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0041498310424</th>\n",
       "      <td>INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...</td>\n",
       "      <td>[en, en, en]</td>\n",
       "      <td>[1, 0.75, 0.93]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0041500007007</th>\n",
       "      <td>Réf 0361 Moutarde French jaune\\nIngrédients: v...</td>\n",
       "      <td>fr</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1901\\nSince\\n100% NATURA\\nClassic\\nMUSTARD\\n80...</td>\n",
       "      <td>[en, fr]</td>\n",
       "      <td>[1, 0.93]</td>\n",
       "      <td>[1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0041500007229</th>\n",
       "      <td>INGREDIENTS: SPIRIT VINEGAR,\\nWATER, MUSTARD S...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>INGREDIENTS: SPIRIT VINEGAR,\\nWATER, MUSTARD S...</td>\n",
       "      <td>[en, fr, en, en, en, en, de]</td>\n",
       "      <td>[0.84, 1, 0.54, 0.71, 0.7, 1, 0.57]</td>\n",
       "      <td>[8, 2, 9, 5, 7, 1, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0041500013107</th>\n",
       "      <td>Poids net:295 m\\ninarédients: vinaiore distilé...</td>\n",
       "      <td>fr</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>Poids net:295 m\\ninarédients: vinaiore distilé...</td>\n",
       "      <td>[fr, fr, en]</td>\n",
       "      <td>[1, 0.9, 0.9]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  extracted_text lang_kept  \\\n",
       "code                                                                         \n",
       "0041498293222  \"Percent Daily Values are based on a 2000\\nNut...        en   \n",
       "0041498310424  INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...        en   \n",
       "0041500007007  Réf 0361 Moutarde French jaune\\nIngrédients: v...        fr   \n",
       "0041500007229  INGREDIENTS: SPIRIT VINEGAR,\\nWATER, MUSTARD S...        en   \n",
       "0041500013107  Poids net:295 m\\ninarédients: vinaiore distilé...        fr   \n",
       "\n",
       "               lang_kept_confidence  \\\n",
       "code                                  \n",
       "0041498293222              1.000000   \n",
       "0041498310424              0.893333   \n",
       "0041500007007              0.930000   \n",
       "0041500007229              0.570000   \n",
       "0041500013107              0.900000   \n",
       "\n",
       "                                                           texts  \\\n",
       "code                                                               \n",
       "0041498293222  \"Percent Daily Values are based on a 2000\\nNut...   \n",
       "0041498310424  INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...   \n",
       "0041500007007  1901\\nSince\\n100% NATURA\\nClassic\\nMUSTARD\\n80...   \n",
       "0041500007229  INGREDIENTS: SPIRIT VINEGAR,\\nWATER, MUSTARD S...   \n",
       "0041500013107  Poids net:295 m\\ninarédients: vinaiore distilé...   \n",
       "\n",
       "                                      langs  \\\n",
       "code                                          \n",
       "0041498293222                          [en]   \n",
       "0041498310424                  [en, en, en]   \n",
       "0041500007007                      [en, fr]   \n",
       "0041500007229  [en, fr, en, en, en, en, de]   \n",
       "0041500013107                  [fr, fr, en]   \n",
       "\n",
       "                                       confidences                   keys  \n",
       "code                                                                       \n",
       "0041498293222                                  [1]                    [1]  \n",
       "0041498310424                      [1, 0.75, 0.93]              [2, 1, 3]  \n",
       "0041500007007                            [1, 0.93]                 [1, 3]  \n",
       "0041500007229  [0.84, 1, 0.54, 0.71, 0.7, 1, 0.57]  [8, 2, 9, 5, 7, 1, 6]  \n",
       "0041500013107                        [1, 0.9, 0.9]              [2, 1, 3]  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>lang_kept</th>\n",
       "      <th>lang_kept_confidence</th>\n",
       "      <th>texts</th>\n",
       "      <th>langs</th>\n",
       "      <th>confidences</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0041498293222</th>\n",
       "      <td>\"Percent Daily Values are based on a 2000\\nNut...</td>\n",
       "      <td>en</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Percent Daily Values are based on a 2000\\nNut...</td>\n",
       "      <td>[en]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0041498310424</th>\n",
       "      <td>INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...</td>\n",
       "      <td>[en, en, en]</td>\n",
       "      <td>[1, 0.75, 0.93]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  extracted_text lang_kept  \\\n",
       "code                                                                         \n",
       "0041498293222  \"Percent Daily Values are based on a 2000\\nNut...        en   \n",
       "0041498310424  INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...        en   \n",
       "\n",
       "               lang_kept_confidence  \\\n",
       "code                                  \n",
       "0041498293222              1.000000   \n",
       "0041498310424              0.893333   \n",
       "\n",
       "                                                           texts  \\\n",
       "code                                                               \n",
       "0041498293222  \"Percent Daily Values are based on a 2000\\nNut...   \n",
       "0041498310424  INGREDIENTS: WHOLE ROLLED OATS,\\nMILLED CANE S...   \n",
       "\n",
       "                      langs      confidences       keys  \n",
       "code                                                     \n",
       "0041498293222          [en]              [1]        [1]  \n",
       "0041498310424  [en, en, en]  [1, 0.75, 0.93]  [2, 1, 3]  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_barcode('0041500007007')\n",
    "#df.loc['0041500007007', \"keys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "  text_cleaned = text.replace(\"\\n\", \" \") #remove line breaks\n",
    "  #text_cleaned = re.sub(\"\\w*([.])\\w+\", \"\", text_cleaned) #remove websites or measures\n",
    "  text_cleaned = re.sub(\"[^A-Za-z0-9 \\-àâäéèêëîïôöùûüÿçÂÊÎÔÛÄËÏÖÜÀÆæÇÉÈŒœÙ]\", \" \", text_cleaned) #kepp alphanum only\n",
    "  text_cleaned = re.sub(\"\\w*([0-9]{0,}[,|\\.]{0,}[0-9])\\w*\", \" \", text_cleaned) #remove measure elements\n",
    "  text_cleaned = re.sub(r\"\\b([a-zA-Z]{1})\\b\", \" \", text_cleaned) # remove isolated letters ex --> g g g g g\n",
    "  text_cleaned = re.sub(\"( +- +)\", \" \", text_cleaned)\n",
    "  text_cleaned = re.sub(r\" +\", \" \", text_cleaned) # remove multiple spaces\n",
    "\n",
    "  #text_cleaned = \"\".join([ch for ch in text_cleaned if (ch.isalnum() or ch == \" \" or ch ==\"'\" or ch ==\"-\")])\n",
    "  return text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_cleaned\"] = df[\"extracted_text\"].apply(lambda x: text_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MONOPRIX Gourmet VA Pralin NOS CONSEILS DE PRÉPARATION Sortez la bûchette de son emballage et déposez-la sur une assiette de présentation environ minutes avant de la déguster BÜCHETTES GLACÉES COMPOSÉES UNE CRÈME GLACÉE AU CHOCOLAT NOIR AVEC ÉCLATS DE CARAMEL AU BEURRE ET À LA CRÈME DÉCORÉES UN FLOCAGE AUX CHOCOLATS DE GANACHE AU CHOCOLAT NOIR ET DE CUBES DE CARAMEL AU LAIT SURGELÉES INGRÉDIENTS Crème glacée au chocolat noir avec éclats de caramel aromatique au beurre et à la crème lait entier sucre chocolat noir du Costa Rica à de cacao pâte de cacao du Costa Rica sucre beurre de cacao arôme naturel de vanille caramel aromatique au beurre et à la crème sucre sirop de glucose beurre crème eau crème fraîche cacao en poudre Afrique de Ouest -sirop de glucose déshydraté lait écrémé en poudre lactose et protéines de lait émulsifiant mono- et diglycérides acides gras-stabilisants farine de graines de caroube gomme guar Flocage aux chocolats chocolat au lait sucre beurre de cacao lait entier en poudre pâte de cacao émulsifiant lécithines de soja arôme naturel de vanille beurre de cacao huile de tournesol chocolat noir à de cacao pâte de cacao sucre beurre de cacao émulsifiant lécithines de soja arôme naturel de vanille Ganache au chocolat noir chocolat noir à de cacao pâte de cacao sucre beurre de cacao émulsifiant lécithines de soja arôme naturel de vanille crème crème stabilisant carraghénanes sirop de glucose de maïs Cubes de caramel au lait sucre lait concentré sucré sirop de glucose lait entier en poudre humectant sorbitols- émulsifiants lécithines de soja mono- et diglycérides acides gras Traces æuf de céréales contenant du gluten et de fruits à coque Les informations en gras sont destinées aux personnes intolérantes ou allergiques INFORMATIONS NUTRITIONNELLES NES Pour une bûchette de environ Pour kJ kJ Energie kcal kcal Matières grasses dont saturées Glucides dont sucres Fibres Protéines Sel CONDITIONS DE CONSERVATION Plusieurs mois dans le compartiment à un réfrigérateur ou dans un congélateur jusqu à la date de durabilité minimale NE JAMAIS RECONGELER UN PRODUIT DÉCONGELÉ Cet emballage contient bûchettes de environ POIDS NET consommer de préférence avant le de lot voir la date figurant sur le côté de la boîte SERVICE CLIENTS MONOPRIX EMB Service appel gratuits plateau carton étui PENSEZ AU TRI à jeter et boite plastique carton à recycler Distribué par MONOPRIX EXPLOITATION Clichy Cedex www monoprix fr consigne pouvant varier localement www consignesdetri fr valable uniquement pour la France MONOPRIX Gourmet BÛCHETTES GLACÉES crème glacée au chocolat du Costa Rica inclusions de caramel Pour INFORMATIONS NUTRITIONNELLES NES une bûchette de environ Pour kJ kJ kcal kcal Energie Matières grasses dont saturées Glucides dont sucres Fibres Protéines Sel Cet emballage contient bûchettes de environ '"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaner(df.loc['3350033581098', \"extracted_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.set_index(\"code\", drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def worker_cleaner(list_):\n",
    "    return [text_cleaner(x) for x in list_]\n",
    "\n",
    "def chunk_worker(chunk):\n",
    "    text_cleaned_col_idx = np.where(df.columns == \"text_cleaned\")[0][0]\n",
    "    text_list = df.iloc[chunk, text_cleaned_col_idx]\n",
    "    return worker_cleaner(text_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "109750\n"
     ]
    }
   ],
   "source": [
    "chunks = np.array_split(range(df.shape[0]), cpu_count())\n",
    "print(len(chunks))\n",
    "print(len(chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/Anis/opt/anaconda3/envs/py39/lib/python3.9/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/var/folders/h3/z06y751x2hb0vxdvf08fd3z00000gn/T/ipykernel_74832/1634859288.py\", line 6, in chunk_worker\n    text_cleaned_col_idx = np.where(df.columns == \"text_cleaned\")[0][0]\nIndexError: index 0 is out of bounds for axis 0 with size 0\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h3/z06y751x2hb0vxdvf08fd3z00000gn/T/ipykernel_74832/3543409619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmultiple_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmultiple_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/h3/z06y751x2hb0vxdvf08fd3z00000gn/T/ipykernel_74832/3543409619.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmultiple_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmultiple_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/py39/lib/python3.9/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "pool = Pool()\n",
    "multiple_results = [pool.apply_async(chunk_worker, (chunks[i],)) for i in range(cpu_count())]\n",
    "output = [r.get() for r in multiple_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "word_count = df['text_cleaned'].str.split().str.len()\n",
    "sns.histplot(word_count)\n",
    "plt.xlim([0,1000])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268282, 8)\n"
     ]
    }
   ],
   "source": [
    "#fit on the whole french dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df_fr = df[df[\"lang_kept\"]== \"fr\"]\n",
    "print(df_fr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "America' Favourite Nothing adds more flavour Frenchs to more foods than the classic taste of FRENCHS Classic Yellow Mustard natural An American family favourite since it' introduction at the St Louis World' Fair in FRENCH' is great with hotdogs burgers ribs and steaks and is mild enouah to saueeze straight onto salads sandwiches and bagels VINEGAR ' SALT SPICE NDER Poi Inc ngrédients mou vinaigre 'alcooi eau graines de moutarde curcuma paprika épices arome pour dre ' Aconsommer de préférence avant voir emballage Distribué par MEDIASCORE SAS Cons www shoppingstreet Distributed bw FRENCHSFoots aunt of Reckt Benckiser Parsippany RB Reserved Made in USA lmported and Distributed by Bespoke FoodS London Distrbutoda Eurofood Spa-ConSCO MI ProdottoinUSA \n"
     ]
    }
   ],
   "source": [
    "#i = np.random.choice(range(df_fr.shape[0]))\n",
    "i = 1\n",
    "print(i)\n",
    "print(df_fr[\"text_cleaned\"].iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<268282x273288 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18440050 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df = 2, max_df = 0.8)\n",
    "tfidf_matrix_fr = vectorizer.fit_transform(df_fr[\"text_cleaned\"])\n",
    "tfidf_matrix_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_with_highest_scores(scores, words, n_words_to_take):\n",
    "  \"\"\"\n",
    "  takes scores and words of an OCR as inputs and returns \n",
    "  words with highest tfidf scores\n",
    "  \"\"\"\n",
    "  items = [item for item in sorted(zip(scores, words), reverse = True)]\n",
    "  best_items = items[:n_words_to_take]\n",
    "  return best_items, items\n",
    "\n",
    "def get_words_and_scores_from_tfidf_matrix(doc, cols, tfidf_matrix_fr, index_to_word):\n",
    "  \"\"\"\n",
    "  takes a document (line of tfidf matrix) and its words (columns of tfidf matrix\n",
    "  and returns words of the documents with their ifidf scores\n",
    "  columns are the non zero values of the tfidf matrix.\n",
    "  \"\"\"\n",
    "  scores = []\n",
    "  words = []\n",
    "  for col in cols:\n",
    "    word = index_to_word[col] \n",
    "    score = tfidf_matrix_fr[doc, col]\n",
    "    words.append(word)\n",
    "    scores.append(score)\n",
    "  return words, scores\n",
    "\n",
    "index_to_word = {index: word for index, word in zip(vectorizer.vocabulary_.values(), vectorizer.vocabulary_.keys())}\n",
    "\n",
    "def text_selection(doc, index_to_word, df_cleaned, n_words_to_take = 35, tfidf_matrix_fr = tfidf_matrix_fr):\n",
    "  rows, cols = tfidf_matrix_fr[doc].nonzero()\n",
    "  ## extract words and scores from tfidf matrix\n",
    "  words, scores = get_words_and_scores_from_tfidf_matrix(doc, cols, tfidf_matrix_fr, index_to_word)\n",
    "  #extract words with highest score from sentence\n",
    "  best_items, items = get_words_with_highest_scores(scores, words, n_words_to_take)\n",
    "  best_words = [item[1] for item in best_items]\n",
    "  text_selection = \" \".join([word for word in df_cleaned.iloc[doc].split() if word.lower() in best_words])\n",
    "  text_selection_unique = remove_duplicates(text_selection)\n",
    "  return text_selection_unique, items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(text):\n",
    "    D = {word.lower(): word  for word in str(text).split()}\n",
    "    return \" \".join(D.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268282/268282 [00:16<00:00, 16033.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "freq_dict = {}\n",
    "for text in tqdm(df_fr[\"text_cleaned\"]):\n",
    "    for word in remove_duplicates(text).split():\n",
    "        if str(word).lower() in freq_dict:\n",
    "            freq_dict[str(word).lower()] += 1\n",
    "        else:\n",
    "            freq_dict[str(word).lower()] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dic_sorted = {k: v for k, v in sorted(freq_dict.items(), reverse = True, key=lambda item: item[1]) if v > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "\n",
    "def make_barcode(x):\n",
    "    return \"{}/{}/{}/{}\".format(x[:3], x[3:6], x[6:9], x[9:])\n",
    "\n",
    "def make_link_from_barcode(barcode, file = \"image\", df= df):\n",
    "    keys = df.loc[barcode, \"keys\"]\n",
    "    links = []\n",
    "    if file == \"image\": file = \"jpg\"\n",
    "    if file == \"json\": file = \"json\"\n",
    "    barcode_with_slash = make_barcode(barcode)\n",
    "    for key in keys:\n",
    "        link = \"https://world.openfoodfacts.org/images/products/{}/{}.{}\".format(barcode_with_slash, key,file)\n",
    "        links.append(link)\n",
    "    return links\n",
    "\n",
    "def show_images(links):\n",
    "    for link in links:\n",
    "        response = requests.get(link)\n",
    "        image_bytes = io.BytesIO(response.content)\n",
    "        img = Image.open(image_bytes)\n",
    "        img.show()\n",
    "\n",
    "def show_images_from_barcode(barcode):\n",
    "    links = make_link_from_barcode(barcode, file = \"image\")\n",
    "    show_images(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_barcode('0041500007229')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"America's Favourite\\nNothing adds more flavour\\nFrenchs\\nto more foods than the classic\\ntaste of FRENCHS Classic\\nYellow Mustard, 100% natural.\\nAn American family favourite since it's\\nintroduction at the St. Louis World's Fair in 1904!\\nFRENCH'S is great with hotdogs, burgers, ribs and steaks and is\\nmild enouah to saueeze straight onto salads, sandwiches and bagels.\\nVINEGAR\\n'n. SALT.\\nSPICE,\\nNDER\\nPoi\\nInc\\nngrédients\\nmou\\nvinaigre d'alcooi,eau graines de moutarde.S\\ncurcuma, paprika épices,arome, pour dre d'a\\nAconsommer de préférence avant voir emballage\\nDistribué par MEDIASCORE F00D SAS.\\nA Cons\\nwww.shoppingstreet\\n0 41500 00722 9\\nDistributed bw.FRENCHSFoots aunt of Reckt Benckiser\\nParsippany NOTO54-0224 2011 RB.\\nReserved Made in USA\\nlmported and Distributed by Bespoke FoodS\\nLondon SW81\\nDistrbutoda Eurofood Spa-ConSCO (MI)\\nProdottoinUSA\\n0334756\\n113345\\n12 29\\n\""
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fr[\"extracted_text\"].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'America Favourite Nothing adds more flavour Frenchs to more foods than the classic taste of FRENCHS Classic Yellow Mustard natural An American family favourite since it introduction at the St Louis World Fair in FRENCH is great with hotdogs burgers ribs and steaks and is mild enouah to saueeze straight onto salads sandwiches and bagels VINEGAR SALT SPICE NDER Poi Inc ngrédients mou vinaigre alcooi eau graines de moutarde curcuma paprika épices arome pour dre Aconsommer de préférence avant voir emballage Distribué par MEDIASCORE SAS Cons www shoppingstreet Distributed bw FRENCHSFoots aunt of Reckt Benckiser Parsippany RB Reserved Made in USA lmported and Distributed by Bespoke FoodS London Distrbutoda Eurofood Spa-ConSCO MI ProdottoinUSA '"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fr[\"text_cleaned\"].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('America favourite Nothing adds more FRENCHS to FoodS the Classic American introduction is hotdogs and straight onto salads sandwiches bagels NDER alcooi MEDIASCORE shoppingstreet Distributed bw aunt Benckiser RB Reserved lmported Bespoke London Eurofood',\n",
       " [(0.2905362628986267, 'frenchs'),\n",
       "  (0.23920785611856749, 'favourite'),\n",
       "  (0.20332923916603987, 'and'),\n",
       "  (0.1768359684701444, 'distributed'),\n",
       "  (0.1687359458434285, 'classic'),\n",
       "  (0.16373014989214457, 'foods'),\n",
       "  (0.14871808610258716, 'shoppingstreet'),\n",
       "  (0.14871808610258716, 'hotdogs'),\n",
       "  (0.14871808610258716, 'consco'),\n",
       "  (0.14871808610258716, 'bespoke'),\n",
       "  (0.14526813144931336, 'lmported'),\n",
       "  (0.13855708033938752, 'benckiser'),\n",
       "  (0.13695573881185694, 'mediascore'),\n",
       "  (0.1320933008276743, 'eurofood'),\n",
       "  (0.12864334617440049, 'straight'),\n",
       "  (0.12791632069674017, 'alcooi'),\n",
       "  (0.12723086284349164, 'introduction'),\n",
       "  (0.12528068378077836, 'more'),\n",
       "  (0.12378090819021786, 'aunt'),\n",
       "  (0.12071169178925256, 'adds'),\n",
       "  (0.11996193218604251, 'onto'),\n",
       "  (0.11765496081121199, 'bw'),\n",
       "  (0.11735884088624893, 'nothing'),\n",
       "  (0.1165119775327687, 'reserved'),\n",
       "  (0.1157683145278892, 'to'),\n",
       "  (0.11474149007510108, 'bagels'),\n",
       "  (0.1134076447153901, 'rb'),\n",
       "  (0.11094390970128615, 'nder'),\n",
       "  (0.11094390970128615, 'american'),\n",
       "  (0.10934256817375557, 'america'),\n",
       "  (0.10859190324514172, 'the'),\n",
       "  (0.1069088513170924, 'sandwiches'),\n",
       "  (0.10690288032984548, 'is'),\n",
       "  (0.10574363958439614, 'london'),\n",
       "  (0.10509525207793367, 'salads'),\n",
       "  (0.10306764685866406, 'ribs'),\n",
       "  (0.09715681282831279, 'yellow'),\n",
       "  (0.09636929267701376, 'burgers'),\n",
       "  (0.09592046595390388, 'mild'),\n",
       "  (0.09572625526996455, 'family'),\n",
       "  (0.09539377562457478, 'world'),\n",
       "  (0.09381587935893211, 'spice'),\n",
       "  (0.09268036555917067, 'mou'),\n",
       "  (0.09227630061669076, 'great'),\n",
       "  (0.09137210891975812, 'than'),\n",
       "  (0.09001184696745178, 'spa'),\n",
       "  (0.08800619278584379, 'french'),\n",
       "  (0.08689545294278463, 'dre'),\n",
       "  (0.0862446381015024, 'steaks'),\n",
       "  (0.086128900920488, 'in'),\n",
       "  (0.08550950155564424, 'of'),\n",
       "  (0.08509966918721786, 'fair'),\n",
       "  (0.08500080426094676, 'taste'),\n",
       "  (0.0849614853810161, 'poi'),\n",
       "  (0.08431206490606717, 'usa'),\n",
       "  (0.0840363689104847, 'louis'),\n",
       "  (0.08136037618475261, 'mustard'),\n",
       "  (0.08124464792706276, 'vinegar'),\n",
       "  (0.08029029433224785, 'since'),\n",
       "  (0.07930792391398603, 'inc'),\n",
       "  (0.07080715158503466, 'flavour'),\n",
       "  (0.06914341880800232, 'ngrédients'),\n",
       "  (0.06783695081120861, 'cons'),\n",
       "  (0.0641643390402762, 'made'),\n",
       "  (0.06315789376992892, 'natural'),\n",
       "  (0.06289632603529306, 'aconsommer'),\n",
       "  (0.06244662141124828, 'by'),\n",
       "  (0.0612720164395018, 'curcuma'),\n",
       "  (0.060878353672763626, 'mi'),\n",
       "  (0.05939582196724722, 'it'),\n",
       "  (0.05918352341113235, 'with'),\n",
       "  (0.057076634083545075, 'paprika'),\n",
       "  (0.05527691179941815, 'sas'),\n",
       "  (0.055161869484464186, 'distribué'),\n",
       "  (0.054569913752319184, 'st'),\n",
       "  (0.05433252732041954, 'at'),\n",
       "  (0.054086283691893985, 'an'),\n",
       "  (0.050077956734300634, 'arome'),\n",
       "  (0.04845175304174867, 'vinaigre'),\n",
       "  (0.04668056915845757, 'salt'),\n",
       "  (0.0444140243730558, 'moutarde'),\n",
       "  (0.044222652897148974, 'graines'),\n",
       "  (0.04278967628829361, 'épices'),\n",
       "  (0.04246645895020841, 'emballage'),\n",
       "  (0.03451669681622637, 'préférence'),\n",
       "  (0.03434568095654092, 'voir'),\n",
       "  (0.0326848474434488, 'www'),\n",
       "  (0.030054372829300853, 'avant'),\n",
       "  (0.028133728975334112, 'par'),\n",
       "  (0.02810182829492436, 'eau'),\n",
       "  (0.017998167313861117, 'pour')])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_selection(i, index_to_word, df_fr[\"text_cleaned\"], n_words_to_take = 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hv/qx8621252qs2m1jzhhzd4c1r0000gn/T/ipykernel_74806/4105742966.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fr[\"tfidf_selection\"] = [text_selection(i, index_to_word, df_fr[\"text_cleaned\"])[0] for i in range(df_fr.shape[0])]\n"
     ]
    }
   ],
   "source": [
    "df_fr[\"tfidf_selection\"] = [text_selection(i, index_to_word, df_fr[\"text_cleaned\"])[0] for i in range(df_fr.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>lang_kept</th>\n",
       "      <th>lang_kept_confidence</th>\n",
       "      <th>texts</th>\n",
       "      <th>langs</th>\n",
       "      <th>confidences</th>\n",
       "      <th>keys</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>tfidf_selection</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0041500007007</th>\n",
       "      <td>Réf 0361 Moutarde French jaune\\nIngrédients: v...</td>\n",
       "      <td>fr</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1901\\nSince\\n100% NATURA\\nClassic\\nMUSTARD\\n80...</td>\n",
       "      <td>[en, fr]</td>\n",
       "      <td>[1, 0.93]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Réf Moutarde French jaune Ingrédients vinaigre...</td>\n",
       "      <td>Réf moutarde French jaune vinaigre distillé su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0041500007229</th>\n",
       "      <td>America's Favourite\\nNothing adds more flavour...</td>\n",
       "      <td>fr</td>\n",
       "      <td>0.57</td>\n",
       "      <td>INGREDIENTS: SPIRIT VINEGAR,\\nWATER, MUSTARD S...</td>\n",
       "      <td>[en, fr, en, en, en, en, de]</td>\n",
       "      <td>[0.84, 1, 0.54, 0.71, 0.7, 1, 0.57]</td>\n",
       "      <td>[8, 2, 9, 5, 7, 1, 6]</td>\n",
       "      <td>America' Favourite Nothing adds more flavour F...</td>\n",
       "      <td>favourite Nothing adds more FRENCHS to FoodS t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  extracted_text lang_kept  \\\n",
       "code                                                                         \n",
       "0041500007007  Réf 0361 Moutarde French jaune\\nIngrédients: v...        fr   \n",
       "0041500007229  America's Favourite\\nNothing adds more flavour...        fr   \n",
       "\n",
       "               lang_kept_confidence  \\\n",
       "code                                  \n",
       "0041500007007                  0.93   \n",
       "0041500007229                  0.57   \n",
       "\n",
       "                                                           texts  \\\n",
       "code                                                               \n",
       "0041500007007  1901\\nSince\\n100% NATURA\\nClassic\\nMUSTARD\\n80...   \n",
       "0041500007229  INGREDIENTS: SPIRIT VINEGAR,\\nWATER, MUSTARD S...   \n",
       "\n",
       "                                      langs  \\\n",
       "code                                          \n",
       "0041500007007                      [en, fr]   \n",
       "0041500007229  [en, fr, en, en, en, en, de]   \n",
       "\n",
       "                                       confidences                   keys  \\\n",
       "code                                                                        \n",
       "0041500007007                            [1, 0.93]                 [1, 3]   \n",
       "0041500007229  [0.84, 1, 0.54, 0.71, 0.7, 1, 0.57]  [8, 2, 9, 5, 7, 1, 6]   \n",
       "\n",
       "                                                    text_cleaned  \\\n",
       "code                                                               \n",
       "0041500007007  Réf Moutarde French jaune Ingrédients vinaigre...   \n",
       "0041500007229  America' Favourite Nothing adds more flavour F...   \n",
       "\n",
       "                                                 tfidf_selection  \n",
       "code                                                              \n",
       "0041500007007  Réf moutarde French jaune vinaigre distillé su...  \n",
       "0041500007229  favourite Nothing adds more FRENCHS to FoodS t...  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "0.57\n",
      "{'en': 748.146, 'fr': 601.3, 'de': 132.867}\n",
      "{'en': {'confidences': [0.84, 0.54, 0.71, 0.7, 1], 'text_len': 987}, 'fr': {'confidences': [1], 'text_len': 859}, 'de': {'confidences': [0.57], 'text_len': 333}}\n"
     ]
    }
   ],
   "source": [
    "barcode = \"0041500007229\"\n",
    "#barcode = \"0041500007007\"\n",
    "c = df.loc[barcode, \"confidences\"]\n",
    "l = df.loc[barcode, \"langs\"]\n",
    "texts = df.loc[barcode, \"texts\"]\n",
    "\n",
    "lang_to_keep, lang_to_keep_confidence, D, O = get_most_confident_lang(c, l, texts)\n",
    "print(lang_to_keep)\n",
    "print(lang_to_keep_confidence)\n",
    "print(O)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"America's Favourite\\nNothing adds more flavour\\nFrenchs\\nto more foods than the classic\\ntaste of FRENCHS Classic\\nYellow Mustard, 100% natural.\\nAn American family favourite since it's\\nintroduction at the St. Louis World's Fair in 1904!\\nFRENCH'S is great with hotdogs, burgers, ribs and steaks and is\\nmild enouah to saueeze straight onto salads, sandwiches and bagels.\\nVINEGAR\\n'n. SALT.\\nSPICE,\\nNDER\\nPoi\\nInc\\nngrédients\\nmou\\nvinaigre d'alcooi,eau graines de moutarde.S\\ncurcuma, paprika épices,arome, pour dre d'a\\nAconsommer de préférence avant voir emballage\\nDistribué par MEDIASCORE F00D SAS.\\nA Cons\\nwww.shoppingstreet\\n0 41500 00722 9\\nDistributed bw.FRENCHSFoots aunt of Reckt Benckiser\\nParsippany NOTO54-0224 2011 RB.\\nReserved Made in USA\\nlmported and Distributed by Bespoke FoodS\\nLondon SW81\\nDistrbutoda Eurofood Spa-ConSCO (MI)\\nProdottoinUSA\\n0334756\\n113345\\n12 29\\n\""
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "df_fr.loc[i_l[i], \"extracted_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"America' Favourite Nothing adds more flavour Frenchs to more foods than the classic taste of FRENCHS Classic Yellow Mustard natural An American family favourite since it' introduction at the St Louis World' Fair in FRENCH' is great with hotdogs burgers ribs and steaks and is mild enouah to saueeze straight onto salads sandwiches and bagels VINEGAR ' SALT SPICE NDER Poi Inc ngrédients mou vinaigre 'alcooieau graines de moutardeS curcuma paprika épicesarome pour dre ' Aconsommer de préférence avant voir emballage Distribué par MEDIASCORE SAS Cons wwwshoppingstreet Distributed bwFRENCHSFoots aunt of Reckt Benckiser Parsippany RB Reserved Made in USA lmported and Distributed by Bespoke FoodS London Distrbutoda Eurofood Spa-ConSCO MI ProdottoinUSA \""
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fr.loc[i_l[i], \"text_cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0041500007229\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tfidf_selection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tfidf_selection'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/az/Documents/OpenFoodFacts/off-category-classification/dataforgood_ocr/Ocr_notebook.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/az/Documents/OpenFoodFacts/off-category-classification/dataforgood_ocr/Ocr_notebook.ipynb#ch0000053?line=0'>1</a>\u001b[0m i_l \u001b[39m=\u001b[39m df_fr\u001b[39m.\u001b[39mindex\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/az/Documents/OpenFoodFacts/off-category-classification/dataforgood_ocr/Ocr_notebook.ipynb#ch0000053?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(i_l[i])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/az/Documents/OpenFoodFacts/off-category-classification/dataforgood_ocr/Ocr_notebook.ipynb#ch0000053?line=2'>3</a>\u001b[0m df_fr\u001b[39m.\u001b[39;49mloc[i_l[i], \u001b[39m\"\u001b[39;49m\u001b[39mtfidf_selection\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=958'>959</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m    <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=959'>960</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m--> <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=960'>961</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m    <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=961'>962</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=962'>963</a>\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=963'>964</a>\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py:1140\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=1137'>1138</a>\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=1138'>1139</a>\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=1139'>1140</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=1141'>1142</a>\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=1142'>1143</a>\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py:891\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=888'>889</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m section\n\u001b[1;32m    <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=889'>890</a>\u001b[0m         \u001b[39m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=890'>891</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(section, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)[new_key]\n\u001b[1;32m    <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=892'>893</a>\u001b[0m \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mnot applicable\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=963'>964</a>\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=965'>966</a>\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m--> <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=966'>967</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py:1202\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=1199'>1200</a>\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=1200'>1201</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=1201'>1202</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=1150'>1151</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=1151'>1152</a>\u001b[0m     \u001b[39m# GH#5667 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexing.py?line=1152'>1153</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/generic.py:3864\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/generic.py?line=3861'>3862</a>\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/generic.py?line=3862'>3863</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/generic.py?line=3863'>3864</a>\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/generic.py?line=3865'>3866</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/generic.py?line=3866'>3867</a>\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/az/miniforge3/envs/env_tf/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tfidf_selection'"
     ]
    }
   ],
   "source": [
    "i_l = df_fr.index\n",
    "print(i_l[i])\n",
    "df_fr.loc[i_l[i], \"tfidf_selection\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169825"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_[\"moutardes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('favourite Nothing adds more FRENCHS to FoodS the Classic Yellow American introduction is hotdogs ribs and straight onto salads sandwiches bagels NDER épicesarome MEDIASCORE Distributed aunt Benckiser RB Reserved lmported Bespoke London Eurofood',\n",
       " [(0.3017027937185185, 'frenchs'),\n",
       "  (0.24263921208818504, 'favourite'),\n",
       "  (0.20682285999900923, 'and'),\n",
       "  (0.18248503528531385, 'distributed'),\n",
       "  (0.1713466223732942, 'classic'),\n",
       "  (0.16632610990714453, 'foods'),\n",
       "  (0.15085139685925925, 'épicesarome'),\n",
       "  (0.15085139685925925, 'hotdogs'),\n",
       "  (0.15085139685925925, 'consco'),\n",
       "  (0.15085139685925925, 'bespoke'),\n",
       "  (0.14735195377075383, 'lmported'),\n",
       "  (0.14054463489746055, 'benckiser'),\n",
       "  (0.13892032266612847, 'mediascore'),\n",
       "  (0.13504656473997786, 'eurofood'),\n",
       "  (0.1304886915615031, 'straight'),\n",
       "  (0.1290559466338886, 'introduction'),\n",
       "  (0.1271149641092729, 'more'),\n",
       "  (0.1260742102876143, 'aunt'),\n",
       "  (0.12325451231580807, 'adds'),\n",
       "  (0.1216827456192326, 'onto'),\n",
       "  (0.11904231385321881, 'nothing'),\n",
       "  (0.11874918467208993, 'reserved'),\n",
       "  (0.11827629925039461, 'to'),\n",
       "  (0.11638741802797258, 'rb'),\n",
       "  (0.11638741802797258, 'bagels'),\n",
       "  (0.11288797493946717, 'nder'),\n",
       "  (0.11253536264527945, 'american'),\n",
       "  (0.11091105041394737, 'america'),\n",
       "  (0.11027961761709827, 'the'),\n",
       "  (0.1090481806624247, 'is'),\n",
       "  (0.10856718557200325, 'sandwiches'),\n",
       "  (0.10748787260586436, 'london'),\n",
       "  (0.10649656914005856, 'salads'),\n",
       "  (0.10463655857368384, 'ribs'),\n",
       "  (0.09877267918838245, 'yellow'),\n",
       "  (0.09838647937433383, 'mild'),\n",
       "  (0.09775167765834643, 'burgers'),\n",
       "  (0.09714836695705037, 'family'),\n",
       "  (0.09685757368997212, 'world'),\n",
       "  (0.095499554672358, 'spice'),\n",
       "  (0.09447329103316744, 'mou'),\n",
       "  (0.09359997300819602, 'great'),\n",
       "  (0.09295772149772369, 'than'),\n",
       "  (0.09182997912688182, 'spa'),\n",
       "  (0.08937169959261305, 'french'),\n",
       "  (0.08876588449456495, 'dre'),\n",
       "  (0.08847219721671715, 'of'),\n",
       "  (0.08778300674164884, 'in'),\n",
       "  (0.0875039656784352, 'steaks'),\n",
       "  (0.08713234175383744, 'usa'),\n",
       "  (0.08668841808679079, 'poi'),\n",
       "  (0.08642151195119203, 'fair'),\n",
       "  (0.08636074110515678, 'taste'),\n",
       "  (0.08527875965762485, 'louis'),\n",
       "  (0.08276569414283884, 'mustard'),\n",
       "  (0.08263111569403449, 'vinegar'),\n",
       "  (0.08165974241841066, 'since'),\n",
       "  (0.0807602343643738, 'inc'),\n",
       "  (0.07215138908144984, 'flavour'),\n",
       "  (0.07066848213478759, 'ngrédients'),\n",
       "  (0.06975787830082891, 'cons'),\n",
       "  (0.06550308256893174, 'made'),\n",
       "  (0.06453837876177083, 'by'),\n",
       "  (0.06422654232236125, 'aconsommer'),\n",
       "  (0.06420363716248821, 'natural'),\n",
       "  (0.062382331642712945, 'curcuma'),\n",
       "  (0.06208484746623428, 'mi'),\n",
       "  (0.061254208147527446, 'it'),\n",
       "  (0.06015139531369443, 'with'),\n",
       "  (0.05811335804881284, 'paprika'),\n",
       "  (0.05628445497067381, 'sas'),\n",
       "  (0.056026366710158614, 'distribué'),\n",
       "  (0.055799825082630525, 'at'),\n",
       "  (0.05575077553076371, 'st'),\n",
       "  (0.05540016805335146, 'an'),\n",
       "  (0.052939858111037456, 'salt'),\n",
       "  (0.04941131155770108, 'vinaigre'),\n",
       "  (0.045015296583990096, 'graines'),\n",
       "  (0.043211644519597324, 'emballage'),\n",
       "  (0.03521220695419379, 'voir'),\n",
       "  (0.03501657410097769, 'préférence'),\n",
       "  (0.030555619303031818, 'avant'),\n",
       "  (0.028887200058624423, 'par'),\n",
       "  (0.018416301408335292, 'pour')])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_selection(i, index_to_word, df_fr[\"text_cleaned\"], n_words_to_take = 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a1716f42ac06625fc9064efa784cbbcb72acf33b466051d2552a87bcba1e0c5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
